{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dde80fe-023b-40a2-b832-cae45d4d5913",
   "metadata": {},
   "source": [
    "# I. Multithreading I/O tasks\n",
    "\n",
    "Multithreading can be use make our code execute faster.\n",
    "\n",
    "Because of the **Global Interpretor Lock** (Python paradgim) only one thread can be executed at time while the other are waiting. However the GIL doesn't not block I/O operation, so in that case, multithreading can be used for the better.\n",
    "\n",
    "When our code execution is CPU bound, multithreading is inefficient and we should rely on **multiprocessing** instead. Multiprocessing offers the advantage of parallelism however it is requires copying part of the memory space, it is more heavyweight and slower to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad974e85-462f-41ba-bea9-1ca1bb2807f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\Nico\\\\GitRepos\\\\Parallel-Computing\\\\multithreading\\\\01 - write in shared list', 'C:\\\\Users\\\\Nico\\\\anaconda3\\\\python312.zip', 'C:\\\\Users\\\\Nico\\\\anaconda3\\\\DLLs', 'C:\\\\Users\\\\Nico\\\\anaconda3\\\\Lib', 'C:\\\\Users\\\\Nico\\\\anaconda3', '', 'C:\\\\Users\\\\Nico\\\\anaconda3\\\\Lib\\\\site-packages', 'C:\\\\Users\\\\Nico\\\\anaconda3\\\\Lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\Nico\\\\anaconda3\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\Nico\\\\anaconda3\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\Nico\\\\anaconda3\\\\Lib\\\\site-packages\\\\setuptools\\\\_vendor', '..']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# append '..' so that we can go up one directory to import utils\n",
    "module_path = '..'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils import perf_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "244a73ed-6f08-408e-bd95-38cf0c093009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b12953f6-1659-44e5-a084-4c09822dce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from threading import Thread, Lock\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adf79e2-960e-4201-b934-19afd4943c00",
   "metadata": {},
   "source": [
    "## I. Write into a protected shared list\n",
    "\n",
    "In this example we simulated a long I/O task by sleeping 1s. We generate a random number that we store un a shared list. We execute this task n time sequentially and using multithreading.\n",
    "\n",
    "We protect our shared list with a **mutex Lock**, which can be only acquire by one thread at a time so that we protect our data structure against race condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db29e00f-b7f6-4fd6-a8aa-f29cc05cb9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_io_task(shared_list, shared_lock):\n",
    "    \"\"\" Simulate log I/O task \"\"\"\n",
    "    sleep(1)\n",
    "    with shared_lock:\n",
    "        shared_list.append(random.randint(0,9))\n",
    "    return shared_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99c6396e-13ad-4fff-ba7f-d4eb6ebd9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "@perf_decorator\n",
    "def main_not_threaded(n):\n",
    "    \"\"\" Execute n not threaded I/O tasks \"\"\"\n",
    "    shared_list = []\n",
    "    shared_lock = Lock()\n",
    "\n",
    "    for _ in range(n):\n",
    "        long_io_task(shared_list, shared_lock)\n",
    "\n",
    "    print(shared_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99be3c4e-ae36-4d37-9070-29836d31ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@perf_decorator\n",
    "def main_threaded(n):\n",
    "    \"\"\" Execute n threaded I/O tasks \"\"\"\n",
    "    shared_list = []\n",
    "    shared_lock = Lock()\n",
    "\n",
    "    workers = [Thread(target = long_io_task, args=(shared_list, shared_lock))\n",
    "                      for _ in range(n)]\n",
    "    for worker in workers:\n",
    "        worker.start() # start all threads\n",
    "\n",
    "    for worker in workers:\n",
    "        worker.join() # wait for all threads to finish\n",
    "        \n",
    "    print(shared_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "441a087c-eb40-47a5-a67c-df6adc2905a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 8, 7, 8, 4, 2, 7, 8, 2]\n",
      "main_not_threaded execution time 10.01s\n"
     ]
    }
   ],
   "source": [
    "main_not_threaded(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6a69acb-595b-49d2-96e8-ae7cfdebc15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 8, 0, 3, 8, 4, 6, 5, 1, 6]\n",
      "main_threaded execution time 1.01s\n"
     ]
    }
   ],
   "source": [
    "main_threaded(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9746b68d-4629-4145-ba51-b5f45d12a2f4",
   "metadata": {},
   "source": [
    "In that case the threaded option is way more efficient has expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f002b71-55ed-4d71-99c5-e4ddf0f2de5c",
   "metadata": {},
   "source": [
    "## II. Race Condition - What happen if we don't protect our data structure ?\n",
    "\n",
    "In this example, many threads are writing in the same file. If they attempt to access the same file at the same exact time, it can lead to a race condition, and one thread or many threads may not write the information. \n",
    "\n",
    "The file must be proctected by a **mutex lock**. With this lock, only one thread can write in the file while the other are sleeping. In that manner, the writing in file operation become thread safe, but at the cost the acquire/release time of the lock.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fe1bc64f-c9dc-466f-8081-00ce9bf28f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_in_file(filename, lock=None):\n",
    "    \"\"\" Write in filename in append mode no lock\"\"\"\n",
    "    sleep(0.001)\n",
    "    for i in range(100):\n",
    "        if lock:\n",
    "            lock.acquire()\n",
    "            with open(filename, 'a') as f:\n",
    "                sleep(0.01)\n",
    "                f.write(f\"{random.random()}\\n\")\n",
    "            lock.release()\n",
    "        else:\n",
    "            with open(filename, 'a') as f:\n",
    "                sleep(0.01)\n",
    "                f.write(f\"{random.random()}\\n\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dbfe775e-f618-4612-a7f6-d54313899cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_lines_in_file(filename):\n",
    "    \"\"\" Count line number i filename \"\"\"\n",
    "    counter = 0\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            counter +=1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7e32688c-ff22-4c5f-9bf4-23394a04cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@perf_decorator\n",
    "def main_not_protected():\n",
    "    \"\"\" Write with 20 threads in the same file  \"\"\"\n",
    "\n",
    "    fname = \"not_protected.txt\"\n",
    "    \n",
    "    # erase content of previous file\n",
    "    with open(fname, \"w\") as f:\n",
    "        pass\n",
    "    \n",
    "    workers = [Thread(target = write_in_file, args=(fname,)) for _ in range(20)]\n",
    "    \n",
    "    for worker in workers:\n",
    "        worker.start() # start all threads\n",
    "    \n",
    "    for worker in workers:\n",
    "        worker.join() # wait for all threads to finish\n",
    "\n",
    "    n_lines = count_lines_in_file(fname)\n",
    "    print(f\"There are {n_lines} lines in {fname}, there should be {20*100}.\")\n",
    "    print(f\"Missing Line: {20*100-n_lines} lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7c289201-8fb7-43c2-a1d6-96ddf29b7a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1875 lines in not_protected.txt, there should be 2000.\n",
      "Missing Line: 125 lines\n",
      "main_not_protected execution time 1.31s\n"
     ]
    }
   ],
   "source": [
    "main_not_protected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2fe5081d-c593-4aa0-8751-8a404afcc7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@perf_decorator\n",
    "def main_protected():\n",
    "    \"\"\" Write with 20 threads in the same file  \"\"\"\n",
    "\n",
    "    fname = \"protected.txt\"\n",
    "    \n",
    "    # erase content of previous file\n",
    "    with open(fname, \"w\") as f:\n",
    "        pass\n",
    "\n",
    "    lock = Lock()\n",
    "    workers = [Thread(target = write_in_file, args=(fname,lock)) for _ in range(20)]\n",
    "    \n",
    "    for worker in workers:\n",
    "        worker.start() # start all threads\n",
    "    \n",
    "    for worker in workers:\n",
    "        worker.join() # wait for all threads to finish\n",
    "\n",
    "    n_lines = count_lines_in_file(fname)\n",
    "    print(f\"There are {n_lines} lines in {fname}, there should be {20*100}.\")\n",
    "    print(f\"Missing Line: {20*100-n_lines} lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "408c46a2-c3f1-415a-a3e6-a38e297e578d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2000 lines in protected.txt, there should be 2000.\n",
      "Missing Line: 0 lines\n",
      "main_protected execution time 23.43s\n"
     ]
    }
   ],
   "source": [
    "main_protected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "880a7885-5cf8-4a05-8372-6cd5edc6ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "@perf_decorator\n",
    "def main_sequential():\n",
    "    \"\"\" Write with 20 threads in the same file  \"\"\"\n",
    "\n",
    "    fname = \"sequential.txt\"\n",
    "    \n",
    "    # erase content of previous file\n",
    "    with open(fname, \"w\") as f:\n",
    "        pass\n",
    "\n",
    "    for _ in range(20):\n",
    "        write_in_file(fname)\n",
    "\n",
    "    n_lines = count_lines_in_file(fname)\n",
    "    print(f\"There are {n_lines} lines in {fname}, there should be {20*100}.\")\n",
    "    print(f\"Missing Line: {20*100-n_lines} lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "48fe8255-ff54-4d35-8834-a66ac1f561ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2000 lines in sequential.txt, there should be 2000.\n",
      "Missing Line: 0 lines\n",
      "main_sequential execution time 24.28s\n"
     ]
    }
   ],
   "source": [
    "main_sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f649dc6c-e4e9-4e23-ac0f-a128177cb35e",
   "metadata": {},
   "source": [
    "## III. Share data with ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db9d211-d9be-45fb-a255-5b9885646626",
   "metadata": {},
   "source": [
    "ThreadPoolExecutor come from the concurrent.futures module. It has a simpler interface that the threading module and basically do what the multithreading but in a better way. We can use:\n",
    "- executor.submit in a for loop. It creates an iterable where results are stored as they come\n",
    "- execut.map. It creates an iterable where results come in the starting order\n",
    "\n",
    "Also something very interesting with these convenient function is that error will only be raised when we go through the iterator which mean that we can manage the error flow properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "192c0cef-311f-4be6-8039-6e6acf144ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "fe666c5f-214b-4721-9f03-847a5aba1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_something(seconds, raised_sec=None):\n",
    "    sleep(seconds)\n",
    "    if raised_sec and seconds == raised_sec:\n",
    "        raise ValueError(f\"Cannot accept sleeping for {raised_sec} s.\")\n",
    "    return f'Done {seconds} seconds ...'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcee2e76-9323-499a-ac92-39fa29a2adff",
   "metadata": {},
   "source": [
    "### a. using a loop: result came in the finished order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ce76ff58-e145-4aeb-9e6e-d53baefb0f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1 seconds ...\n",
      "Error has been properly managed: Cannot accept sleeping for 2 s.\n",
      "Done 3 seconds ...\n",
      "Done 5 seconds ...\n",
      "main execution time 5.01s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Future at 0x1de5037b230 state=finished returned str>,\n",
       " <Future at 0x1de5037ac30 state=finished returned str>,\n",
       " <Future at 0x1de50379940 state=finished raised ValueError>,\n",
       " <Future at 0x1de50378d70 state=finished returned str>]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@perf_decorator\n",
    "def main():\n",
    "    \n",
    "    # the pool made the decision on how to affect worker\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        secs = [5, 3, 2, 1]\n",
    "\n",
    "        results = [executor.submit(do_something, sec, raised_sec=2) for sec in secs]\n",
    "    \n",
    "        # iterator than we can loop over that will yield result as completed\n",
    "        for f in concurrent.futures.as_completed(results):\n",
    "            try:\n",
    "                print(f.result())\n",
    "            except ValueError as err:\n",
    "                print(f\"Error has been properly managed: {err}\")\n",
    "\n",
    "    return results\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9741a286-1494-47ed-803e-6e8aa764d569",
   "metadata": {},
   "source": [
    "Threads come in order from the fastest to slowest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2482fcd-b620-48f5-9d01-9d6f29682c68",
   "metadata": {},
   "source": [
    "### b. using a loop: result came in the finished order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9ca80818-2311-4fc1-b9d5-f009cc510a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 5 seconds ...\n",
      "Done 3 seconds ...\n",
      "Done 2 seconds ...\n",
      "Done 1 seconds ...\n",
      "main execution time 5.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object Executor.map.<locals>.result_iterator at 0x000001DE50681F30>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@perf_decorator\n",
    "def main():\n",
    "    \n",
    "    # the pool made the decision on how to affect worker\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        secs = [5, 3, 2, 1]\n",
    "\n",
    "        results = executor.map(do_something, secs)\n",
    "    \n",
    "        # iterator than we can loop over that will yield result in execution order\n",
    "        for res in results:\n",
    "            print(res)\n",
    "\n",
    "    return results\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf399529-4fca-4d3c-9451-e017a05c2a0a",
   "metadata": {},
   "source": [
    "Threads come in execution order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65315350-43c2-4733-9e7f-f75fa73c54b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
